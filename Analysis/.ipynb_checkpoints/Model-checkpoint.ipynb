{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d7c390-88bd-4747-b3c0-f47c473f457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "# ---------- PATHS ----------\n",
    "X_noleak_path        = '../../Retrieval/Data_Combined/dota_X_final_noleak.csv'\n",
    "X_noleak_scaled_path = '../../Retrieval/Data_Combined/dota_X_final_noleak_scaled.csv'\n",
    "y_path               = '../../Retrieval/Data_Combined/dota_y_final.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867dbb5b-51a2-4a48-bf61-de5817e006d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features and labels\n",
    "X_noleak = pd.read_csv(X_noleak_path)\n",
    "X_noleak_scaled = pd.read_csv(X_noleak_scaled_path)\n",
    "y = pd.read_csv(y_path).squeeze()  # convert 1-col DataFrame to Series\n",
    "\n",
    "print(\"X_noleak shape:       \", X_noleak.shape)\n",
    "print(\"X_noleak_scaled shape:\", X_noleak_scaled.shape)\n",
    "print(\"y shape:              \", y.shape)\n",
    "\n",
    "print(\"\\nClass balance (radiant_win):\")\n",
    "print(y.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd69d34-94e7-4be1-9587-8df378877810",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2  # 80% train, 20% test\n",
    "\n",
    "# For Random Forest: use unscaled\n",
    "X_train_rf, X_test_rf, y_train, y_test = train_test_split(\n",
    "    X_noleak,\n",
    "    y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "# For Logistic Regression: use scaled\n",
    "X_train_lr, X_test_lr, _, _ = train_test_split(\n",
    "    X_noleak_scaled,\n",
    "    y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train_rf.shape[0])\n",
    "print(\"Test size: \", X_test_rf.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed1ed4-01fc-4433-ba01-4689ac1bb3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d0fc51-6185-4108-bfdf-9bf951d6f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='lbfgs',        # good default\n",
    "    n_jobs=-1,             # use all cores if available\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train_lr, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test_lr)\n",
    "\n",
    "evaluate_model(\"Logistic Regression (no-leak, scaled)\", y_test, y_pred_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e044b-3e14-4217-a773-4d9685a91dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf.fit(X_train_rf, y_train)\n",
    "y_pred_rf = rf.predict(X_test_rf)\n",
    "\n",
    "evaluate_model(\"Random Forest (no-leak)\", y_test, y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e26e21-ffe4-4cfc-bbc9-73ceadeff4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "feat_names = X_noleak.columns\n",
    "\n",
    "feat_imp = pd.DataFrame({\n",
    "    \"feature\": feat_names,\n",
    "    \"importance\": importances,\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"Top 20 most important features (Random Forest):\")\n",
    "feat_imp.head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
